---
title: Sairam Tabibu's work experience
layout: default
excerpt: All the companies and places Sairam Tabibu has worked at, and the jobs
permalink: /experience
---

[<img class="experience-picture" src="{{site.url}}{{site.baseurl}}/images/experience/iiith.png">](http://cvit.iiit.ac.in/){:target="_blank"}

_November 2017 --- present_

### [CVIT, IIIT Hyderabad](http://cvit.iiit.ac.in/){:target="_blank"}

**Research Fellow**, supervisor: [Prof. C.V. Jawahar](https://faculty.iiit.ac.in/~jawahar/){:target="_blank"}

<br />


# EDUCATION

[<img class="experience-picture" src="{{site.url}}{{site.baseurl}}/images/experience/iitbhu.png">](http://www.iitbhu.ac.in/){:target="_blank"}

_2013 --- 2017_

### [Indian Institute of Technology, (BHU), Varanasi](http://www.iitbhu.ac.in/){:target="_blank"}, India

Bachelors Degree in Electronics Engineering

<br />


# RESEARCH PROJECTS

[<img class="experience-picture" src="{{site.url}}{{site.baseurl}}/images/experience/ntu.png">](http://www.ntu.edu.sg/Pages/home.aspx){:target="_blank"}

_January-2017 --- April-2017_

### Lexical and Visual Analysis to Identify Posts Warranting Empathetic Responses

[**NTU, Singapore**](http://www.ntu.edu.sg/Pages/home.aspx) --- under [Prof. Erik Cambria](http://sentic.net/erikcambria/){:target="_blank"}, School of Computer Science and Engineering

We worked on understanding the sentiment that a person elicits on different posts present on different social media sites, on the topics of abuse or mental health. We propose a method supported by hand-crafted features to judge if the post requires an empathetic response. The model is trained upon posts from various web-pages
and corresponding comments, on both the captions and the Images. We were able to obtain 80% accuracy in tagging posts requiring empathetic responses.

A [research paper]({{site.url}}{{site.baseurl}}/docs/publications/FLAIRS.pdf){:target="_blank"} based on this work has been published in [AAAI Publications](https://aaai.org/ocs/index.php/FLAIRS/FLAIRS17/paper/view/15505){:target="_blank"} in proceedings of the Proceedings of the Thirtieth International Florida Artificial Intelligence Research Society Conference, [FLAIRS 2017](https://aaai.org/ocs/index.php/FLAIRS/FLAIRS17/paper/view/15505){:target="_blank"}.

| [**Research paper**]({{site.url}}{{site.baseurl}}/docs/publications/FLAIRS.pdf){:target="_blank"}: Jaiswal, Mimansa, Sairam Tabibu, and Erik Cambria. "“Hang in There”: Lexical and Visual Analysis to Identify Posts Warranting Empathetic Responses." (2017). |


<br />

[<img class="experience-picture" src="{{site.url}}{{site.baseurl}}/images/experience/kgp.jpg">](http://www.iitkgp.ac.in/){:target="_blank"}

_September-2016 --- December-2016_

### Multimodal Analysis for Deception Detection

[**NTU Singapore**](http://www.ntu.edu.sg/Pages/home.aspx) --- under [Dr. Rajiv Bajpai](https://scholar.google.com.sg/citations?user=hHZR1xkAAAAJ&hl=en){:target="_blank"}, School of Computer Science and Engineering

We worked on developing a data driven method for automatic deception detection in real-life trial data using visual and verbal cues. Using OpenFace with facial action unit recognition, we analyze the movement of facial features of the witness when posed with questions and the acoustic patterns using OpenSmile. We then perform a lexical analysis on the spoken words, emphasizing the use of pauses and utterance breaks, feeding that to a Support Vector Machine to test deceit or truth prediction. We then try out a method to incorporate utterance-based fusion of visual and lexical analysis, using string based matching.

A [research paper]({{site.url}}{{site.baseurl}}/docs/publications/ICDMW.pdf){:target="_blank"} based on this work has been published in [IEEE Explore](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7836768){:target="_blank"} in proceedings of the 16th International Conference on Data Mining Workshops, [ICDM 2016](https://aaai.org/ocs/index.php/FLAIRS/FLAIRS17/paper/view/15505){:target="_blank"}. 

| [**Research paper**]({{site.url}}{{site.baseurl}}/docs/publications/ICDMW.pdf){:target="_blank"}: Jaiswal, Mimansa, Sairam Tabibu, and Rajiv Bajpai. "The Truth and Nothing But the Truth: Multimodal Analysis for Deception Detection." ICDM Workshops. 2016. |


<br />

# RESEARCH INTERNSHIPS

[<img class="experience-picture" src="{{site.url}}{{site.baseurl}}/images/experience/leuven.png">](https://www.kuleuven.be/english/){:target="_blank"}

_Summer 2013_

### Implementation of Carry-Free Arithmetic Operations in FPGA

[**KU Leuven, Belgium**](https://www.kuleuven.be/english/) --- under [Prof. Ingrid Verbauwhede](https://www.kuleuven.be/wieiswie/en/person/00018159){:target="_blank"}, Computer Security & Industrial Applications, ESAT

I worked on the carry-free implementations of arithmetic operations of addition, subtraction and multiplication. Binary numbers are first converted to a recoded digit format that eliminates carry propagation. I designed the truth tables for this conversion, as well as subsequent addition, subtraction and multiplication. I then simplified the circuits into Product-of-Sums form, and coded them in Verilog. The time taken by these circuits were compared with standard implementation.

A [single-author research paper]({{site.url}}{{site.baseurl}}/docs/publications/2018_NCC.pdf){:target="_blank"} based on this work has been written.

| [**Research paper**]({{site.url}}{{site.baseurl}}/docs/publications/2018_NCC.pdf){:target="_blank"}: V. Voleti, "Carry-Free Implementations of Arithmetic Operations in FPGA" |

[Report](https://github.com/voletiv/summer_2013_KULeuven/blob/master/Leuven_Report/KULeuven_Report.pdf){:target="_blank"} | [Presentation](https://github.com/voletiv/summer_2013_KULeuven/blob/master/Leuven_Presentation/Implementation_of_Carry-Free_Arithmetic_Primitives_for_Prime_Field_Elliptic_Curve_Cryptography.pdf){:target="_blank"} | [GitHub](https://github.com/voletiv/summer_2013_KULeuven){:target="_blank"} repository containing report and presentation

<br />

[<img class="experience-picture" src="{{site.url}}{{site.baseurl}}/images/experience/kgp.jpg">](http://www.iitkgp.ac.in/){:target="_blank"}

_Summer 2012_

### Fingertip Gesture Recognizer using HMMs

[**IIT Kharagpur, India**](http://www.iitkgp.ac.in/) --- under [Prof. Aurobinda Routray](http://www.aroutray.org/){:target="_blank"}, Electrical Engineering

I first implemented Hidden Markov Models (HMM) in MATLAB from scratch, and verified the implementation outputs with those of standard implementation. I then made a simple gesture recognizer in MATLAB using HMMs.

[Report](https://github.com/voletiv/summer_2012_HMM_FingerTipGestureRecognition/blob/master/Vikram\%20Voleti\%20\%5B09EE3501\%5D\%20Summer\%202012\%20Internship\%20Report.pdf){:target="_blank"} | [Presentation](https://github.com/voletiv/summer_2012_HMM_FingerTipGestureRecognition/blob/master/Ppt.pdf){:target="_blank"} | [GitHub](https://github.com/voletiv/summer_2012_HMM_FingerTipGestureRecognition){:target="_blank"} repository containing report, presentation, code files, and results

<br />

[<img class="experience-picture" src="{{site.url}}{{site.baseurl}}/images/experience/imperial.jpg">](https://www.imperial.ac.uk/){:target="_blank"}

_Summer 2011_

### Measurement of Intra-die Power Variation in Sub-nm FPGA’s

[**Imperial College, London**](https://www.imperial.ac.uk/) --- under [Prof. Peter Cheung](http://www.imperial.ac.uk/people/p.cheung){:target="_blank"}, Electrical and Electronic Engineering

I experimented with an FPGA, and measured the power consumption among the LookUp Tables (LUTs) within it. An automated workflow for the measurement of power across the FPGA was made, by first implementing a circuit in each LUT, measuring the power on an oscilloscope using the JTAG terminals on the FPGA, recording the oscilloscope's readings in MATLAB, and plotting graphs from MATLAB.

[Presentation](https://github.com/voletiv/summer_2011_FPGA_Imperial_College_London/blob/master/An Automated Flow for Intra-Die Power Variation Measurement.pdf){:target="_blank"} | [GitHub](https://github.com/voletiv/summer_2011_FPGA_Imperial_College_London){:target="_blank"} repository containing presentation, certificate, and recommendation letter from Prof. Peter Cheung


